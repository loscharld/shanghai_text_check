# doc_similarity
从数据库里抽取数据集，基于gensim的doc2vec做文档的语义相似度

# 项目介绍
随着互联网对生活的影响不断增加，人们面临着越来越汹涌的网络数据洪流的冲击，这股数据洪流中占比最大的就是文本数据。如何处理海量文本数据，是人们亟待解决的一个问题。
在文本挖掘领域，文本相似度计算技术是联系上层应用系统和下层文本表示模型、分词系统等基础技术的纽带。

# 项目最终效果
根据甲方要求，最后提供两个接口：
1、多篇文档放入同一个目录下，返回每两篇文档之间的相似度（设定阈值），找出重复的文档和同一领域的文档。
2、输入一段摘要或多段文字或一篇文档，返回数据库里的10篇最相似的文档以及与输入段落相似度（设定阈值）极高的段落


# 项目运行方式
1、配置要求：要求配置cx_Oracle数据库及相应的python依赖包。本项目使用oracle数据库作为存储.
2、训练模型：train_model.py.
3、服务接口：interface.py.
3、回滚数据：interface_tow_compare.py  client1.py    200_interface.py  200_client.py.
4、多篇文档关联度本地测试：interface_bendi.py，client_duopian.py.

# 总结
1、本项目从数据库里提取数据集，数据库数据2W多条，都为行业领域内的重要论文。
2、本项目以业务驱动，从数据库里提取文档数据，每篇文档经过去停用词，去标点符号，
引用jieba的TF_IDF关键词抽取接口提取关键词。将关键词集合放入gensim，训练doc2vec，保存模型。
3、多篇文档放入同一个目录下，返回每两篇文档之间的相似度：
难点：1、直接提取每篇文档的关键词，文档向量为所有关键词的词向量的加权和，后标准化。以余弦相似度
作为每两篇文档相似的衡量指标。经人工验证：效果不是很好，原因是论文里有很多无关的一样的词，导致
相似度偏高。
解决方案：深度挖掘文档的中文摘要，研究内容，创新点，技术关键等方面；采用符合评判逻辑，从两方面进行
比对，一是中文摘要（反应整篇文档的核心思想）之间进行比对，二是将研究内容，创新点，技术关键等内容进行
拼接，然后进行互相比对。谁的相似度值高，最终的相似度就取谁。
4、有些文档是没有中文摘要和研究内容的，这些文档如何取中心思想内容？
采用TextRank算法抽取自动摘要，以自动摘要作为文档的中心思想内容，再进行比对。
最后的相似度取值就比较符合真实的两篇文档之间的相似度。
5、输入一段摘要或多段文字或一篇文档，返回数据库里的10篇最相似的文档以及与输入段落相似度（设定阈值）
极高的段落：
输入一段摘要或多段文字或一篇文档，经过去停用词，去标点符号后，提取关键词，从模型中找出最相似的前十篇文档
（模型中出来的是文档的index和相似度值）；根据index从数据库中找出对应的文档内容和文档的绝对路径；经验证，
返回的十篇文档中，本文档大部分出现在首位置，个别出现在其它位置，效果极好。
添加段落相似度：比如输入一段中文摘要，可以从返回的10篇文档中找到这段中文摘要，并把它显示出来。
github:https://github.com/loscharld/shanghai_text_check






